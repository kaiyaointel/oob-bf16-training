diff --git a/eval_voc.py b/eval_voc.py
index f62d2c8..2487a2f 100644
--- a/eval_voc.py
+++ b/eval_voc.py
@@ -37,7 +37,7 @@ parser.add_argument('-v', '--version', default='yolo_v2',
 parser.add_argument('-d', '--dataset', default='VOC',
                     help='VOC or COCO dataset')
 parser.add_argument('--trained_model', type=str,
-                    default='weights_yolo_v2/yolo_v2_72.2.pth', 
+                    default='weights/yolo_v2_250epoch_77.1_78.1.pth', 
                     help='Trained state_dict file path to open')
 parser.add_argument('--save_folder', default='eval/', type=str,
                     help='File path to save results')
@@ -51,24 +51,48 @@ parser.add_argument('--voc_root', default=VOC_ROOT,
                     help='Location of VOC root directory')
 parser.add_argument('--cleanup', default=True, type=str2bool,
                     help='Cleanup and remove results files following eval')
+parser.add_argument('--ipex', action='store_true', default=False,
+                    help='Use ipex')
+# parser.add_argument('--jit', action='store_true', default=False,
+#                     help='Use jit script')
+parser.add_argument('--precision', default='float32',
+                    help='precision, "float32" or "bfloat16"')
+parser.add_argument('--max_iters', default=500, type=int, 
+                    help='max number to run.')
+parser.add_argument('--warmup', default=10, type=int, 
+                    help='warmup number.')
+parser.add_argument('--arch', default=None, type=str, 
+                    help='model name.')
+parser.add_argument('--profile', action='store_true',
+                     help='Trigger profile on current topology.')
+parser.add_argument('--channels_last', type=int, default=1, help='use channels last format')
 
 args = parser.parse_args()
 
 if not os.path.exists(args.save_folder):
     os.mkdir(args.save_folder)
 
-if torch.cuda.is_available():
-    if args.cuda:
+if args.cuda:
+    if torch.cuda.is_available():
         torch.set_default_tensor_type('torch.cuda.FloatTensor')
         cudnn.benchmark = True
         device = torch.device("cuda")
-    if not args.cuda:
+    else:
         print("WARNING: It looks like you have a CUDA device, but aren't using \
               CUDA.  Run with --cuda for optimal eval speed.")
         torch.set_default_tensor_type('torch.FloatTensor')
         device = torch.device("cpu")
+elif args.ipex:
+    import intel_pytorch_extension as ipex
+    print("Running with IPEX...")
+    if args.precision == 'bfloat16':
+        # Automatically mix precision
+        ipex.enable_auto_mixed_precision(mixed_dtype=torch.bfloat16)
+        print("Running with bfloat16...")
+    device = ipex.DEVICE
 else:
     torch.set_default_tensor_type('torch.FloatTensor')
+    device = torch.device("cpu")
 
 YEAR = '2007'
 devkit_path = args.voc_root + 'VOC' + YEAR
@@ -142,7 +166,8 @@ def get_output_dir(name, phase):
 def get_voc_results_file_template(image_set, cls):
     # VOCdevkit/VOC2007/results/det_test_aeroplane.txt
     filename = 'det_' + image_set + '_%s.txt' % (cls)
-    filedir = os.path.join(devkit_path, 'results')
+    # filedir = os.path.join(devkit_path, 'results')
+    filedir = 'results'
     if not os.path.exists(filedir):
         os.makedirs(filedir)
     path = os.path.join(filedir, filename)
@@ -155,6 +180,8 @@ def write_voc_results_file(all_boxes, dataset):
         filename = get_voc_results_file_template(set_type, cls)
         with open(filename, 'wt') as f:
             for im_ind, index in enumerate(dataset.ids):
+                if im_ind >= len(all_boxes[cls_ind]):
+                    break
                 dets = all_boxes[cls_ind][im_ind]
                 if dets == []:
                     continue
@@ -167,7 +194,8 @@ def write_voc_results_file(all_boxes, dataset):
 
 
 def do_python_eval(output_dir='output', use_07=True):
-    cachedir = os.path.join(devkit_path, 'annotations_cache')
+    # cachedir = os.path.join(devkit_path, 'annotations_cache')
+    cachedir = os.path.join('results', 'annotations_cache')
     aps = []
     # The PASCAL VOC metric changed in 2010
     use_07_metric = use_07
@@ -346,6 +374,8 @@ def voc_eval(detpath,
 
 def test_net(net, dataset, device, top_k):
     num_images = len(dataset)
+    if args.max_iters > 0 and (args.max_iters + args.warmup) < num_images:
+        num_images = args.max_iters + args.warmup
     # all detections are collected into:
     #    all_boxes[cls][image] = N x 5 array of detections in
     #    (x1, y1, x2, y2, score)
@@ -360,9 +390,24 @@ def test_net(net, dataset, device, top_k):
     for i in range(num_images):
         im, gt, h, w = dataset.pull_item(i)
 
-        x = Variable(im.unsqueeze(0)).to(device)
+        if args.channels_last:
+            x = Variable(im.unsqueeze(0)).to(memory_format=torch.channels_last)
+        else:
+            x = Variable(im.unsqueeze(0)).to(device)
         _t['im_detect'].tic()
-        detections = net(x)
+        if args.profile:
+            with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU]) as prof:
+                if args.precision == "bfloat16":
+                    with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                        detections = net(x)
+                else:
+                    detections = net(x)
+        else:
+            if args.precision == "bfloat16":
+                with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                    detections = net(x)
+            else:
+                detections = net(x)
         detect_time = _t['im_detect'].toc(average=False)
         bboxes, scores, cls_inds = detections
         scale = np.array([[w, h, w, h]])
@@ -383,6 +428,20 @@ def test_net(net, dataset, device, top_k):
         print('im_detect: {:d}/{:d} {:.3f}s'.format(i + 1,
                                                     num_images, detect_time))
 
+    print('Throughput:{:.3f} samples/s'.format(1 / _t['im_detect'].average_time))
+    print('Latency: {:.3f} ms'.format(_t['im_detect'].average_time * 1000))
+    if args.profile:
+        import pathlib
+        timeline_dir = str(pathlib.Path.cwd()) + '/timeline/'
+        if not os.path.exists(timeline_dir):
+            os.makedirs(timeline_dir)
+        timeline_file = timeline_dir + 'timeline-' + str(torch.backends.quantized.engine) + '-' + \
+                    "yolo2" + str(i) + '-' + str(os.getpid()) + '.json'
+        print(timeline_file)
+        prof.export_chrome_trace(timeline_file)
+        # table_res = prof.key_averages().table(sort_by="cpu_time_total")
+        # self.save_profile_result(timeline_dir + torch.backends.quantized.engine + "_result_average.xlsx", table_res)
+
     with open(det_file, 'wb') as f:
         pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)
 
@@ -395,6 +454,26 @@ def evaluate_detections(box_list, output_dir, dataset):
     do_python_eval(output_dir)
 
 
+def save_profile_result(filename, table):
+    import xlsxwriter
+    workbook = xlsxwriter.Workbook(filename)
+    worksheet = workbook.add_worksheet()
+    keys = ["Name", "Self CPU total %", "Self CPU total", "CPU total %" , "CPU total", \
+            "CPU time avg", "Number of Calls"]
+    for j in range(len(keys)):
+        worksheet.write(0, j, keys[j])
+
+    lines = table.split("\n")
+    for i in range(3, len(lines)-4):
+        words = lines[i].split(" ")
+        j = 0
+        for word in words:
+            if not word == "":
+                worksheet.write(i-2, j, word)
+                j += 1
+    workbook.close()
+
+
 if __name__ == '__main__':
     num_classes = len(labelmap)
 
@@ -402,31 +481,39 @@ if __name__ == '__main__':
     if args.version == 'yolo_v2':
         from models.yolo_v2 import myYOLOv2
         net = myYOLOv2(device, input_size=cfg['min_dim'], num_classes=num_classes, anchor_size=config.ANCHOR_SIZE)
-    
     elif args.version == 'yolo_v3':
         from models.yolo_v3 import myYOLOv3
         net = myYOLOv3(device, input_size=cfg['min_dim'], num_classes=num_classes, anchor_size=config.MULTI_ANCHOR_SIZE)
-    
     elif args.version == 'slim_yolo_v2':
         from models.slim_yolo_v2 import SlimYOLOv2    
         net = SlimYOLOv2(device, input_size=cfg['min_dim'], num_classes=num_classes, anchor_size=config.ANCHOR_SIZE)
         print('Let us eval slim-yolo-v2 on the VOC0712 dataset ......')
-
     elif args.version == 'tiny_yolo_v3':
         from models.tiny_yolo_v3 import YOLOv3tiny
         net = YOLOv3tiny(device, input_size=cfg['min_dim'], num_classes=num_classes, anchor_size=config.TINY_MULTI_ANCHOR_SIZE)
         print('Let us eval tiny-yolo-v3 on the VOC0712 dataset ......')
 
     # load net
-    net.load_state_dict(torch.load(args.trained_model, map_location='cuda'))
+    if args.cuda:
+        net.load_state_dict(torch.load(args.trained_model, map_location='cuda'))
+    else:
+        net.load_state_dict(torch.load(args.trained_model, map_location='cpu'))
     net.eval()
     print('Finished loading model!')
     # load data
     dataset = VOCDetection(args.voc_root, [('2007', set_type)],
                            BaseTransform(net.input_size, mean=(0.406, 0.456, 0.485), std=(0.225, 0.224, 0.229)),
                            VOCAnnotationTransform())
-    net = net.to(device)
-    
+    if args.channels_last:
+        net_oob = net
+        net_oob = net_oob.to(memory_format=torch.channels_last)
+        net = net_oob
+        print("---- Use channels last format.")
+    else:
+        net = net.to(device)
+    # if args.jit:
+    #     net = torch.jit.script(net)
+
     # evaluation
     with torch.no_grad():
         test_net(net, dataset, device, args.top_k)
