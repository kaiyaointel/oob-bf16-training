diff --git a/dcgan/main.py b/dcgan/main.py
index b426db3..2a61776 100644
--- a/dcgan/main.py
+++ b/dcgan/main.py
@@ -12,6 +12,7 @@ import torchvision.datasets as dset
 import torchvision.transforms as transforms
 import torchvision.utils as vutils
 
+import time
 
 parser = argparse.ArgumentParser()
 parser.add_argument('--dataset', required=True, help='cifar10 | lsun | mnist |imagenet | folder | lfw | fake')
@@ -32,6 +33,7 @@ parser.add_argument('--netD', default='', help="path to netD (to continue traini
 parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')
 parser.add_argument('--manualSeed', type=int, help='manual seed')
 parser.add_argument('--classes', default='bedroom', help='comma separated list of classes for the lsun data set')
+parser.add_argument('--bf16Train', action='store_true', help='enable autocast for bf16 training')
 
 opt = parser.parse_args()
 print(opt)
@@ -194,6 +196,28 @@ class Discriminator(nn.Module):
 
         return output.view(-1, 1).squeeze(1)
 
+class AverageMeter(object):  #kyao (whole class)
+    """Computes and stores the average and current value"""
+    def __init__(self, name, fmt=':f'):
+        self.name = name
+        self.fmt = fmt
+        self.reset()
+
+    def reset(self):
+        self.val = 0
+        self.avg = 0
+        self.sum = 0
+        self.count = 0
+
+    def update(self, val, n=1):
+        self.val = val
+        self.sum += val * n
+        self.count += n
+        self.avg = self.sum / self.count
+
+    def __str__(self):
+        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'
+        return fmtstr.format(**self.__dict__)
 
 netD = Discriminator(ngpu).to(device)
 netD.apply(weights_init)
@@ -201,7 +225,7 @@ if opt.netD != '':
     netD.load_state_dict(torch.load(opt.netD))
 print(netD)
 
-criterion = nn.BCELoss()
+criterion = nn.L1Loss() #kyao changed from BSELoss to L1Loss otherwise RtError: found time Long but expected Float
 
 fixed_noise = torch.randn(opt.batchSize, nz, 1, 1, device=device)
 real_label = 1
@@ -211,7 +235,10 @@ fake_label = 0
 optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
 optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
 
+batch_time = AverageMeter('Time', ':6.3f') #kyao
+
 for epoch in range(opt.niter):
+    end = time.time() #kyao
     for i, data in enumerate(dataloader, 0):
         ############################
         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
@@ -222,11 +249,19 @@ for epoch in range(opt.niter):
         batch_size = real_cpu.size(0)
         label = torch.full((batch_size,), real_label, device=device)
 
-        output = netD(real_cpu)
-        errD_real = criterion(output, label)
+        if opt.bf16Train is True:
+            with torch.cuda.amp.autocast(enabled=True):
+                output = netD(real_cpu)
+                errD_real = criterion(output, label)
+        else:
+            output = netD(real_cpu)
+            errD_real = criterion(output, label)
         errD_real.backward()
         D_x = output.mean().item()
-
+        
+        batch_time.update(time.time() - end) #kyao
+        end = time.time() #kyao
+        
         # train with fake
         noise = torch.randn(batch_size, nz, 1, 1, device=device)
         fake = netG(noise)
@@ -260,7 +295,12 @@ for epoch in range(opt.niter):
             vutils.save_image(fake.detach(),
                     '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),
                     normalize=True)
-
+    ### performance computation #kyao
+    latency = batch_time.avg / opt.batchSize * 1000 #kyao
+    throughput = opt.batchSize / batch_time.avg #kyao
+    print('training latency: %3.0f ms on %d epoch'%(latency, epoch)) #kyao
+    print('training throughput: %3.0f fps on %d epoch'%(throughput, epoch)) #kyao
+        
     # do checkpointing
     torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))
     torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))
