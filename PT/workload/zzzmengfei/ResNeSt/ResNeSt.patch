diff --git a/scripts/torch/verify.py b/scripts/torch/verify.py
index ec96fa0..82824a9 100644
--- a/scripts/torch/verify.py
+++ b/scripts/torch/verify.py
@@ -11,6 +11,7 @@ from __future__ import print_function
 import os
 import argparse
 from tqdm import tqdm
+import time
 
 import torch
 import torch.nn as nn
@@ -48,6 +49,20 @@ class Options():
                             help='put the path to resuming file if needed')
         parser.add_argument('--verify', type=str, default=None,
                             help='put the path to resuming file if needed')
+        parser.add_argument('--ipex', action='store_true', default=False,
+                    help='use ipex')
+        parser.add_argument('--jit', action='store_true', default=False,
+                            help='use ipex')
+        parser.add_argument('--precision', default="float32",
+                                help='precision, "float32" or "bfloat16"')
+        parser.add_argument('--warmup', type=int, default=10,
+                            help='number of warmup')
+        parser.add_argument('--max_iters', type=int, default=500,
+                            help='max number of iterations to run')
+        parser.add_argument('--dummy', action='store_true', default=False,
+                            help='use dummy data')
+        parser.add_argument('--channels_last', type=int, default=1, help='use channels last format')
+        parser.add_argument('--profile', action='store_true', help='Trigger profile on current topology.')
         self.parser = parser
 
     def parse(self):
@@ -55,34 +70,63 @@ class Options():
         return args
 
 
+def save_profile_result(filename, table):
+    import xlsxwriter
+    workbook = xlsxwriter.Workbook(filename)
+    worksheet = workbook.add_worksheet()
+    keys = ["Name", "Self CPU total %", "Self CPU total", "CPU total %" , "CPU total", \
+            "CPU time avg", "Number of Calls"]
+    for j in range(len(keys)):
+        worksheet.write(0, j, keys[j])
+
+    lines = table.split("\n")
+    for i in range(3, len(lines)-4):
+        words = lines[i].split(" ")
+        j = 0
+        for word in words:
+            if not word == "":
+                worksheet.write(i-2, j, word)
+                j += 1
+    workbook.close()
+
+
 def main():
     # init the args
     args = Options().parse()
+
+    if args.ipex:
+        import intel_pytorch_extension as ipex
+        print("Running with IPEX...")
+        if args.precision == "bfloat16":
+            # Automatically mix precision
+            ipex.enable_auto_mixed_precision(mixed_dtype=torch.bfloat16)
+            print('Running with bfloat16...')
+
     args.cuda = not args.no_cuda and torch.cuda.is_available()
-    print(args)
     torch.manual_seed(args.seed)
     if args.cuda:
         torch.cuda.manual_seed(args.seed)
-    # init dataloader
-    interp = PIL.Image.BILINEAR if args.crop_size < 320 else PIL.Image.BICUBIC
-    base_size = args.base_size if args.base_size is not None else int(1.0 * args.crop_size / 0.875)
-    transform_val = transforms.Compose([
-        ECenterCrop(args.crop_size),
-        transforms.ToTensor(),
-        transforms.Normalize(mean=[0.485, 0.456, 0.406],
-                             std=[0.229, 0.224, 0.225]),
-    ])
-    valset = ImageNetDataset(transform=transform_val, train=False)
-    val_loader = torch.utils.data.DataLoader(
-        valset, batch_size=args.batch_size, shuffle=False,
-        num_workers=args.workers, pin_memory=True if args.cuda else False)
+    if not args.dummy:
+        # init dataloader
+        interp = PIL.Image.BILINEAR if args.crop_size < 320 else PIL.Image.BICUBIC
+        base_size = args.base_size if args.base_size is not None else int(1.0 * args.crop_size / 0.875)
+        transform_val = transforms.Compose([
+            ECenterCrop(args.crop_size),
+            transforms.ToTensor(),
+            transforms.Normalize(mean=[0.485, 0.456, 0.406],
+                                 std=[0.229, 0.224, 0.225]),
+        ])
+        valset = ImageNetDataset(transform=transform_val, train=False)
+        val_loader = torch.utils.data.DataLoader(
+            valset, batch_size=args.batch_size, shuffle=False,
+            num_workers=args.workers, pin_memory=True if args.cuda else False)
     
     # init the model
     model_kwargs = {}
 
-    assert args.model in torch.hub.list('zhanghang1989/ResNeSt', force_reload=True)
-    model = torch.hub.load('zhanghang1989/ResNeSt', args.model, pretrained=True)
-    print(model)
+    assert args.model in torch.hub.list('zhanghang1989/ResNeSt', force_reload=False)
+    model = torch.hub.load('zhanghang1989/ResNeSt', args.model, pretrained=False)
+    # print(model)
 
     if args.cuda:
         model.cuda()
@@ -107,22 +151,104 @@ def main():
                 format(args.resume))
 
     model.eval()
+
+    if args.ipex:
+        model.to(ipex.DEVICE)
+        if args.jit:
+            data = torch.randn(args.batch_size, 3, args.crop_size, args.crop_size)
+            model = torch.jit.trace(model, data.to(ipex.DEVICE))
+    elif args.channels_last:
+        model_oob = model
+        model_oob.to(memory_format=torch.channels_last)
+        if args.jit:
+            data = torch.randn(args.batch_size, 3, args.crop_size, args.crop_size)
+            model_oob = torch.jit.trace(model_oob, data.to(memory_format=torch.channels_last))
+        model = model_oob
+
     top1 = AverageMeter()
     top5 = AverageMeter()
+    batch_time = AverageMeter()
     is_best = False
-    tbar = tqdm(val_loader, desc='\r')
-    for batch_idx, (data, target) in enumerate(tbar):
-        if args.cuda:
-            data, target = data.cuda(), target.cuda()
-        with torch.no_grad():
-            output = model(data)
-            acc1, acc5 = accuracy(output, target, topk=(1, 5))
-            top1.update(acc1[0], data.size(0))
-            top5.update(acc5[0], data.size(0))
+    if args.dummy:
+        max_iters = args.max_iters + args.warmup
+        for batch_idx in range(max_iters):
+            data = torch.randn(args.batch_size, 3, args.crop_size, args.crop_size)
+            target = torch.arange(1, args.batch_size + 1).long()
+            if batch_idx >= args.warmup:
+                start = time.time()
+            if args.ipex:
+                data, target = data.to(ipex.DEVICE), target.to(ipex.DEVICE)
+            elif args.cuda:
+                data, target = data.cuda(), target.cuda()
+            elif args.channels_last:
+                try:
+                    data, target = data.to(memory_format=torch.channels_last), target.to(memory_format=torch.channels_last)
+                except:
+                    print("Input NHWC failed! Use normal input.")
+
+            with torch.no_grad():
+                if args.profile:
+                    with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU]) as prof:
+                        if args.precision == "bfloat16":
+                            with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                                output = model(data)
+                        else:
+                            output = model(data)
+                else:
+                    if args.precision == "bfloat16":
+                        with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                            output = model(data)
+                    else:
+                        output = model(data)
+            if batch_idx >= args.warmup:
+                batch_time.update(time.time() - start)
+
+            if batch_idx % 10 == 0:
+                print('iters: {:d}/{:d}, {:0.3f}({:0.3f}).'.format(batch_idx + 1, max_iters, batch_time.val, batch_time.avg))
+
+            if batch_idx >= max_iters -1:
+                break
+    else:
+        tbar = tqdm(val_loader, desc='\r')
+        max_iters = min(args.max_iters + args.warmup, len(tbar)) if args.max_iters > 0 else len(tbar)
+        for batch_idx, (data, target) in enumerate(tbar):
+            if batch_idx >= args.warmup:
+                start = time.time()
+            if args.ipex:
+                data, target = data.to(ipex.DEVICE), target.to(ipex.DEVICE)
+            elif args.cuda:
+                data, target = data.cuda(), target.cuda()
+
+            with torch.no_grad():
+                output = model(data)
+                acc1, acc5 = accuracy(output, target, topk=(1, 5))
+                top1.update(acc1[0], data.size(0))
+                top5.update(acc5[0], data.size(0))
+            if batch_idx >= args.warmup:
+                batch_time.update(time.time() - start)
+
+            tbar.set_description('Top1: %.3f | Top5: %.3f'%(top1.avg, top5.avg))
 
-        tbar.set_description('Top1: %.3f | Top5: %.3f'%(top1.avg, top5.avg))
+            if batch_idx >= max_iters -1:
+                break
 
-    print('Top1 Acc: %.3f | Top5 Acc: %.3f '%(top1.avg, top5.avg))
+        print('Top1 Acc: %.3f | Top5 Acc: %.3f '%(top1.avg, top5.avg))
+    latency = batch_time.avg / args.batch_size * 1000
+    perf = args.batch_size / batch_time.avg
+    print('inference latency: %0.3f ms' % latency)
+    print('inference Throughput: %0.3f fps' % perf)
+    #
+    if args.profile:
+        import pathlib
+        timeline_dir = str(pathlib.Path.cwd()) + '/timeline/'
+        if not os.path.exists(timeline_dir):
+            os.makedirs(timeline_dir)
+        timeline_file = timeline_dir + 'timeline-' + str(torch.backends.quantized.engine) + '-' + \
+                    "resnest" + str(batch_idx) + '-' + str(os.getpid()) + '.json'
+        print(timeline_file)
+        prof.export_chrome_trace(timeline_file)
+        # table_res = prof.key_averages().table(sort_by="cpu_time_total")
+        # self.save_profile_result(timeline_dir + torch.backends.quantized.engine + "_result_average.xlsx", table_res)
 
 class ECenterCrop:
     """Crop the given PIL Image and resize it to desired size.
@@ -179,12 +305,12 @@ class AverageMeter(object):
         self.reset()
 
     def reset(self):
-        #self.val = 0
+        self.val = 0
         self.sum = 0
         self.count = 0
 
     def update(self, val, n=1):
-        #self.val = val
+        self.val = val
         self.sum += val * n
         self.count += n
 
