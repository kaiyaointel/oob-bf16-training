diff --git a/pygcn/train.py b/pygcn/train.py
index dca2d47..cb23569 100644
--- a/pygcn/train.py
+++ b/pygcn/train.py
@@ -4,7 +4,7 @@ from __future__ import print_function
 import time
 import argparse
 import numpy as np
-
+import os
 import torch
 import torch.nn.functional as F
 import torch.optim as optim
@@ -19,6 +19,7 @@ parser.add_argument('--no-cuda', action='store_true', default=False,
 parser.add_argument('--fastmode', action='store_true', default=False,
                     help='Validate during training pass.')
 parser.add_argument('--seed', type=int, default=42, help='Random seed.')
+parser.add_argument('--arch', type=str, default="", help='model name')
 parser.add_argument('--epochs', type=int, default=200,
                     help='Number of epochs to train.')
 parser.add_argument('--lr', type=float, default=0.01,
@@ -29,9 +30,31 @@ parser.add_argument('--hidden', type=int, default=16,
                     help='Number of hidden units.')
 parser.add_argument('--dropout', type=float, default=0.5,
                     help='Dropout rate (1 - keep probability).')
+parser.add_argument('--evaluate', action='store_true', default=False,
+                    help='evaluation only')
+parser.add_argument('--ipex', action='store_true', default=False,
+                    help='use ipex')
+# parser.add_argument('--jit', action='store_true', default=False,
+#                     help='use ipex')
+parser.add_argument('--precision', default="float32",
+                        help='precision, "float32" or "bfloat16"')
+parser.add_argument('--warmup', type=int, default=10,
+                    help='number of warmup')
+parser.add_argument('--max_iters', type=int, default=1000,
+                    help='max number of iterations to run')
+parser.add_argument('--profile', action='store_true', default=False,
+                    help='Trigger profile on current topology.')
+parser.add_argument('--channels_last', type=int, default=1, help='use channels last format')
 
 args = parser.parse_args()
 args.cuda = not args.no_cuda and torch.cuda.is_available()
+if args.ipex:
+    import intel_pytorch_extension as ipex
+    print("Running with IPEX...")
+    if args.precision == "bfloat16":
+        # Automatically mix precision
+        ipex.enable_auto_mixed_precision(mixed_dtype=torch.bfloat16)
+        print('Running with bfloat16...')
 
 np.random.seed(args.seed)
 torch.manual_seed(args.seed)
@@ -49,6 +72,13 @@ model = GCN(nfeat=features.shape[1],
 optimizer = optim.Adam(model.parameters(),
                        lr=args.lr, weight_decay=args.weight_decay)
 
+if args.ipex:
+    features = features.to(ipex.DEVICE)
+    adj = adj.to(ipex.DEVICE)
+    labels = labels.to(ipex.DEVICE)
+    idx_train = idx_train.to(ipex.DEVICE)
+    idx_val = idx_val.to(ipex.DEVICE)
+    idx_test = idx_test.to(ipex.DEVICE)
 if args.cuda:
     model.cuda()
     features = features.cuda()
@@ -83,24 +113,82 @@ def train(epoch):
           'loss_val: {:.4f}'.format(loss_val.item()),
           'acc_val: {:.4f}'.format(acc_val.item()),
           'time: {:.4f}s'.format(time.time() - t))
-
-
-def test():
+def save_profile_result(filename, table):
+    import xlsxwriter
+    workbook = xlsxwriter.Workbook(filename)
+    worksheet = workbook.add_worksheet()
+    keys = ["Name", "Self CPU total %", "Self CPU total", "CPU total %" , "CPU total", \
+            "CPU time avg", "Number of Calls"]
+    for j in range(len(keys)):
+        worksheet.write(0, j, keys[j])
+
+    lines = table.split("\n")
+    for i in range(3, len(lines)-4):
+        words = lines[i].split(" ")
+        j = 0
+        for word in words:
+            if not word == "":
+                worksheet.write(i-2, j, word)
+                j += 1
+    workbook.close()
+
+def test(model, adj, features):
     model.eval()
-    output = model(features, adj)
+    if args.ipex:
+        model.to(ipex.DEVICE)
+        # if args.jit:
+        #     model = torch.jit.trace(model, (features, adj))
+    elif args.channels_last:
+        model_oob = model
+        model_oob = model_oob.to(memory_format=torch.channels_last)
+        model = model_oob
+    
+    for i in range(args.max_iters + args.warmup):
+        if i == args.warmup - 1:
+            start = time.time()
+        if args.profile:
+            with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU]) as prof:
+                if args.precision == "bfloat16":
+                    with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                        output = model(features, adj)
+                else:
+                    output = model(features, adj)
+        else:
+            if args.precision == "bfloat16":
+                with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                    output = model(features, adj)
+            else:
+                output = model(features, adj)
+
+    total_time = time.time() - start
     loss_test = F.nll_loss(output[idx_test], labels[idx_test])
     acc_test = accuracy(output[idx_test], labels[idx_test])
     print("Test set results:",
           "loss= {:.4f}".format(loss_test.item()),
           "accuracy= {:.4f}".format(acc_test.item()))
-
+    latency = total_time / args.max_iters * 1000
+    perf = args.max_iters / total_time
+    print('inference latency: %0.3f ms' % latency)
+    print('inference Throughput: %0.3f samples/s' % perf)
+
+    #
+    if args.profile:
+        import pathlib
+        timeline_dir = str(pathlib.Path.cwd()) + '/timeline/'
+        if not os.path.exists(timeline_dir):
+            os.makedirs(timeline_dir)
+        timeline_file = timeline_dir + 'timeline-' + str(torch.backends.quantized.engine) + '-' + \
+                    "gcn" + str(i) + '-' + str(os.getpid()) + '.json'
+        print(timeline_file)
+        prof.export_chrome_trace(timeline_file)
+        # table_res = prof.key_averages().table(sort_by="cpu_time_total")
+        # save_profile_result(timeline_dir + torch.backends.quantized.engine + "_result_average.xlsx", table_res)
 
 # Train model
-t_total = time.time()
-for epoch in range(args.epochs):
-    train(epoch)
-print("Optimization Finished!")
-print("Total time elapsed: {:.4f}s".format(time.time() - t_total))
-
-# Testing
-test()
+if not args.evaluate:
+    t_total = time.time()
+    for epoch in range(args.epochs):
+        train(epoch)
+    print("Optimization Finished!")
+    print("Total time elapsed: {:.4f}s".format(time.time() - t_total))
+test(model, adj, features)
