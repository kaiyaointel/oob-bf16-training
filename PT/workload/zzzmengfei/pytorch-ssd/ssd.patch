diff --git a/eval_ssd.py b/eval_ssd.py
index 5923915..6f82b8c 100644
--- a/eval_ssd.py
+++ b/eval_ssd.py
@@ -14,10 +14,12 @@ import logging
 import sys
 from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite, create_mobilenetv2_ssd_lite_predictor
 from vision.ssd.mobilenetv3_ssd_lite import create_mobilenetv3_large_ssd_lite, create_mobilenetv3_small_ssd_lite
+import os
+import time
 
 
 parser = argparse.ArgumentParser(description="SSD Evaluation on VOC Dataset.")
-parser.add_argument('--net', default="vgg16-ssd",
+parser.add_argument('--net', default="mb1-ssd",
                     help="The network architecture, it should be of mb1-ssd, mb1-ssd-lite, mb2-ssd-lite or vgg16-ssd.")
 parser.add_argument("--trained_model", type=str)
 
@@ -25,13 +27,25 @@ parser.add_argument("--dataset_type", default="voc", type=str,
                     help='Specify dataset type. Currently support voc and open_images.')
 parser.add_argument("--dataset", type=str, help="The root directory of the VOC dataset or Open Images dataset.")
 parser.add_argument("--label_file", type=str, help="The label file path.")
-parser.add_argument("--use_cuda", type=str2bool, default=True)
+parser.add_argument("--model_name", type=str, help="The model names.")
+parser.add_argument("--use_cuda", type=str2bool, default=False)
 parser.add_argument("--use_2007_metric", type=str2bool, default=True)
 parser.add_argument("--nms_method", type=str, default="hard")
 parser.add_argument("--iou_threshold", type=float, default=0.5, help="The threshold of Intersection over Union.")
 parser.add_argument("--eval_dir", default="eval_results", type=str, help="The directory to store evaluation results.")
 parser.add_argument('--mb2_width_mult', default=1.0, type=float,
                     help='Width Multiplifier for MobilenetV2')
+parser.add_argument('--ipex', action='store_true', default=False,
+                    help='use intel pytorch extension')
+parser.add_argument('--precision', type=str, default="float32",
+                    help='precision, float32, bfloat16')
+parser.add_argument('--jit', action='store_true', default=False,
+                    help='enable ipex jit fusionpath')
+parser.add_argument('--channels_last', type=int, default=1, help='use channels last format')
+parser.add_argument('--num_warmup', type=int, default=10, help='warmup')
+parser.add_argument('--num_iters', type=int, default=0, help='iterations')
+parser.add_argument('--profile', action='store_true', help='Trigger profile on current topology.')
+
 args = parser.parse_args()
 DEVICE = torch.device("cuda:0" if torch.cuda.is_available() and args.use_cuda else "cpu")
 
@@ -120,6 +134,26 @@ def compute_average_precision_per_class(num_true_cases, gt_boxes, difficult_case
         return measurements.compute_average_precision(precision, recall)
 
 
+def save_profile_result(filename, table):
+    import xlsxwriter
+    workbook = xlsxwriter.Workbook(filename)
+    worksheet = workbook.add_worksheet()
+    keys = ["Name", "Self CPU total %", "Self CPU total", "CPU total %" , "CPU total", \
+            "CPU time avg", "Number of Calls"]
+    for j in range(len(keys)):
+        worksheet.write(0, j, keys[j])
+
+    lines = table.split("\n")
+    for i in range(3, len(lines)-4):
+        words = lines[i].split(" ")
+        j = 0
+        for word in words:
+            if not word == "":
+                worksheet.write(i-2, j, word)
+                j += 1
+    workbook.close()
+
+
 if __name__ == '__main__':
     eval_path = pathlib.Path(args.eval_dir)
     eval_path.mkdir(exist_ok=True)
@@ -153,12 +187,49 @@ if __name__ == '__main__':
 
     timer.start("Load Model")
     net.load(args.trained_model)
-    net = net.to(DEVICE)
+    if args.ipex:
+        import intel_pytorch_extension as ipex
+        net = net.to(device = ipex.DEVICE)
+        if args.jit:
+            print("running jit fusion path\n")
+        else:
+            print("using ipex model to do inference\n")
+        if args.precision=="bfloat16":
+            conf = ipex.AmpConf(torch.bfloat16)
+            print("running bf16 evalation step\n")
+        else:
+            conf = ipex.AmpConf(None)
+            print("running fp32 evalation step\n")
+    else:
+        net = net.to(DEVICE)
     print(f'It took {timer.end("Load Model")} seconds to load the model.')
+
+    if args.channels_last:
+        oob_net = net
+        oob_net = oob_net.to(memory_format=torch.channels_last)
+        net = oob_net
+        print("---- Use channels last format.")
+
     if args.net == 'vgg16-ssd':
-        predictor = create_vgg_ssd_predictor(net, nms_method=args.nms_method, device=DEVICE)
+        if args.ipex:
+            if args.jit:
+                dummy_inputs = torch.randn(1, 3, 300, 300).to(ipex.DEVICE)
+                trace_net = torch.jit.trace(net, dummy_inputs)
+                predictor = create_vgg_ssd_predictor(trace_net, nms_method=args.nms_method, device=ipex.DEVICE)
+            else:
+                predictor = create_vgg_ssd_predictor(net, nms_method=args.nms_method, device=ipex.DEVICE)
+        else:
+            predictor = create_vgg_ssd_predictor(net, nms_method=args.nms_method, device=DEVICE)
     elif args.net == 'mb1-ssd':
-        predictor = create_mobilenetv1_ssd_predictor(net, nms_method=args.nms_method, device=DEVICE)
+        if args.ipex:
+            if args.jit:
+                dummy_inputs = torch.randn(1, 3, 300, 300).to(ipex.DEVICE)
+                trace_net = torch.jit.trace(net, dummy_inputs)
+                predictor = create_mobilenetv1_ssd_predictor(trace_net, nms_method=args.nms_method, device=ipex.DEVICE)
+            else:
+                predictor = create_mobilenetv1_ssd_predictor(net, nms_method=args.nms_method, device=ipex.DEVICE)
+        else:
+            predictor = create_mobilenetv1_ssd_predictor(net, nms_method=args.nms_method, device=DEVICE)
     elif args.net == 'mb1-ssd-lite':
         predictor = create_mobilenetv1_ssd_lite_predictor(net, nms_method=args.nms_method, device=DEVICE)
     elif args.net == 'sq-ssd-lite':
@@ -171,22 +242,86 @@ if __name__ == '__main__':
         sys.exit(1)
 
     results = []
+    all_time = 0
     for i in range(len(dataset)):
+        if args.num_iters != 0 and i >= args.num_iters:
+            break
+        if i == args.num_warmup:
+            all_time = 0
         print("process image", i)
         timer.start("Load Image")
         image = dataset.get_image(i)
         print("Load Image: {:4f} seconds.".format(timer.end("Load Image")))
-        timer.start("Predict")
-        boxes, labels, probs = predictor.predict(image)
-        print("Prediction: {:4f} seconds.".format(timer.end("Predict")))
-        indexes = torch.ones(labels.size(0), 1, dtype=torch.float32) * i
-        results.append(torch.cat([
-            indexes.reshape(-1, 1),
-            labels.reshape(-1, 1).float(),
-            probs.reshape(-1, 1),
-            boxes + 1.0  # matlab's indexes start from 1
-        ], dim=1))
+
+        if args.ipex:
+            with ipex.AutoMixPrecision(conf, running_mode="inference"):
+                start_time = time.time()
+                if args.profile:
+                    with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU]) as prof:
+                        if args.precision == 'bfloat16':
+                            with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                                boxes, labels, probs = predictor.predict(image)
+                        else:
+                            boxes, labels, probs = predictor.predict(image)
+                else:
+                    if args.precision == 'bfloat16':
+                        with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                            boxes, labels, probs = predictor.predict(image)
+                    else:
+                        boxes, labels, probs = predictor.predict(image)
+                end_time = time.time() - start_time
+                print("Prediction: {:4f} seconds.".format(end_time))
+                all_time += end_time
+                indexes = torch.ones(labels.size(0), 1, dtype=torch.float32) * i
+                results.append(torch.cat([
+                    indexes.reshape(-1, 1),
+                    labels.reshape(-1, 1).float(),
+                    probs.reshape(-1, 1),
+                    boxes + 1.0  # matlab's indexes start from 1
+                ], dim=1))
+        else:
+            if args.profile:
+                with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU]) as prof:
+                    start_time = time.time()
+                    if args.precision == 'bfloat16':
+                        with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                            boxes, labels, probs = predictor.predict(image)
+                    else:
+                        boxes, labels, probs = predictor.predict(image)
+                    end_time = time.time() - start_time
+                    print("Prediction: {:4f} seconds.".format(end_time))
+                all_time += end_time
+            else:
+                start_time = time.time()
+                if args.precision == 'bfloat16':
+                    with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                        boxes, labels, probs = predictor.predict(image)
+                else:
+                    boxes, labels, probs = predictor.predict(image)
+                end_time = time.time() - start_time
+                print("Prediction: {:4f} seconds.".format(end_time))
+                all_time += end_time
+            indexes = torch.ones(labels.size(0), 1, dtype=torch.float32) * i
+            results.append(torch.cat([
+                indexes.reshape(-1, 1),
+                labels.reshape(-1, 1).float(),
+                probs.reshape(-1, 1),
+                boxes + 1.0  # matlab's indexes start from 1
+            ], dim=1))
     results = torch.cat(results)
+    #
+    if args.profile:
+        import pathlib
+        timeline_dir = str(pathlib.Path.cwd()) + '/timeline/'
+        if not os.path.exists(timeline_dir):
+            os.makedirs(timeline_dir)
+        timeline_file = timeline_dir + 'timeline-' + str(torch.backends.quantized.engine) + '-' + \
+                    args.net + str(i) + '-' + str(os.getpid()) + '.json'
+        print(timeline_file)
+        prof.export_chrome_trace(timeline_file)
+        # table_res = prof.key_averages().table(sort_by="cpu_time_total")
+        # self.save_profile_result(timeline_dir + torch.backends.quantized.engine + "_result_average.xlsx", table_res)
+
     for class_index, class_name in enumerate(class_names):
         if class_index == 0: continue  # ignore background
         prediction_path = eval_path / f"det_test_{class_name}.txt"
@@ -217,3 +352,4 @@ if __name__ == '__main__':
         print(f"{class_name}: {ap}")
 
     print(f"\nAverage Precision Across All Classes:{sum(aps)/len(aps)}")
+    print('Throughput is: %f imgs/s' % ((args.num_iters - args.num_warmup) / all_time))
