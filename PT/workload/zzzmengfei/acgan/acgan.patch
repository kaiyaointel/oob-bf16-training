commit 89e640e356e691fe88647ff40d3612b69020f6c8
Author: limengfei <mengfei.li@intel.com>
Date:   Sun Jul 4 19:46:26 2021 +0800

    add acgan int8

diff --git a/implementations/acgan/acgan.py b/implementations/acgan/acgan.py
index d7fa248..37ecb50 100644
--- a/implementations/acgan/acgan.py
+++ b/implementations/acgan/acgan.py
@@ -13,25 +13,51 @@ from torch.autograd import Variable
 import torch.nn as nn
 import torch.nn.functional as F
 import torch
+#import intel_pytorch_extension as ipex
+import time
 
 os.makedirs("images", exist_ok=True)
 
 parser = argparse.ArgumentParser()
-parser.add_argument("--n_epochs", type=int, default=200, help="number of epochs of training")
-parser.add_argument("--batch_size", type=int, default=64, help="size of the batches")
+parser.add_argument("--n_epochs", type=int, default=1, help="number of epochs of training")
+parser.add_argument("--batch_size", type=int, default=16, help="size of the batches")
 parser.add_argument("--lr", type=float, default=0.0002, help="adam: learning rate")
 parser.add_argument("--b1", type=float, default=0.5, help="adam: decay of first order momentum of gradient")
 parser.add_argument("--b2", type=float, default=0.999, help="adam: decay of first order momentum of gradient")
-parser.add_argument("--n_cpu", type=int, default=8, help="number of cpu threads to use during batch generation")
+parser.add_argument("--n_cpu", type=int, default=32, help="number of cpu threads to use during batch generation")
 parser.add_argument("--latent_dim", type=int, default=100, help="dimensionality of the latent space")
 parser.add_argument("--n_classes", type=int, default=10, help="number of classes for dataset")
 parser.add_argument("--img_size", type=int, default=32, help="size of each image dimension")
 parser.add_argument("--channels", type=int, default=1, help="number of image channels")
-parser.add_argument("--sample_interval", type=int, default=400, help="interval between image sampling")
+parser.add_argument("--sample_interval", type=int, default=4, help="interval between image sampling")
+parser.add_argument("--arch", type=str, default="", help="model name")
+parser.add_argument('--outf', default='./model', help='folder to output images and model checkpoints')
+parser.add_argument('--inference', action='store_true', default=False)
+parser.add_argument('--num-warmup', default=10, type=int)
+parser.add_argument('--num-iterations', default=100, type=int)
+parser.add_argument('--ipex', action='store_true', default=False)
+parser.add_argument('--precision', default='float32', help='Precision, "float32" or "bfloat16"')
+parser.add_argument('--jit', action='store_true', default=False)
+parser.add_argument('--profile', action='store_true', default=False ,help='Trigger profile on current topology.')
+parser.add_argument('--channels_last', type=int, default=1, help='use channels last format')
+parser.add_argument('--config_file', type=str, default='./conf.yaml', help='config file for int8 tuning')
 opt = parser.parse_args()
 print(opt)
 
-cuda = True if torch.cuda.is_available() else False
+try:
+    os.makedirs(opt.outf)
+except OSError:
+    pass
+
+if opt.ipex:
+    import intel_pytorch_extension as ipex
+    if opt.precision == "bfloat16":
+        # Automatically mix precision
+        ipex.enable_auto_mixed_precision(mixed_dtype=torch.bfloat16)
+        print("Running with bfloat16...")
+    device = ipex.DEVICE
+else:
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
 
 
 def weights_init_normal(m):
@@ -42,6 +68,12 @@ def weights_init_normal(m):
         torch.nn.init.normal_(m.weight.data, 1.0, 0.02)
         torch.nn.init.constant_(m.bias.data, 0.0)
 
+class _DataLoader(object):
+    def __init__(self, data=None, batch_size=1):
+        self.data = data
+        self.batch_size = batch_size
+    def __iter__(self):
+        yield self.data, self.data[1]
 
 class Generator(nn.Module):
     def __init__(self):
@@ -109,18 +141,12 @@ class Discriminator(nn.Module):
 
 
 # Loss functions
-adversarial_loss = torch.nn.BCELoss()
-auxiliary_loss = torch.nn.CrossEntropyLoss()
+adversarial_loss = torch.nn.BCELoss().to(device)
+auxiliary_loss = torch.nn.CrossEntropyLoss().to(device)
 
 # Initialize generator and discriminator
-generator = Generator()
-discriminator = Discriminator()
-
-if cuda:
-    generator.cuda()
-    discriminator.cuda()
-    adversarial_loss.cuda()
-    auxiliary_loss.cuda()
+generator = Generator().to(device)
+discriminator = Discriminator().to(device)
 
 # Initialize weights
 generator.apply(weights_init_normal)
@@ -145,10 +171,96 @@ dataloader = torch.utils.data.DataLoader(
 optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))
 optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))
 
+cuda = torch.cuda.is_available()
 FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor
 LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor
 
 
+def save_profile_result(filename, table):
+    import xlsxwriter
+    workbook = xlsxwriter.Workbook(filename)
+    worksheet = workbook.add_worksheet()
+    keys = ["Name", "Self CPU total %", "Self CPU total", "CPU total %" , "CPU total", \
+            "CPU time avg", "Number of Calls"]
+    for j in range(len(keys)):
+        worksheet.write(0, j, keys[j])
+
+    lines = table.split("\n")
+    for i in range(3, len(lines)-4):
+        words = lines[i].split(" ")
+        j = 0
+        for word in words:
+            if not word == "":
+                worksheet.write(i-2, j, word)
+                j += 1
+    workbook.close()
+
+def generate(netG, batchsize, device):
+    fixed_noise = Variable(FloatTensor(np.random.normal(0, 1, (10 ** 2, opt.latent_dim))))
+
+    # nhwc
+    if opt.channels_last:
+        netG_oob, fixed_noise_oob = netG, fixed_noise
+        netG_oob = netG_oob.to(memory_format=torch.channels_last)
+        try:
+            fixed_noise_oob = fixed_noise_oob.to(memory_format=torch.channels_last)
+        except:
+            print("Input NHWC failed! Use normal input.")
+        netG, fixed_noise = netG_oob, fixed_noise_oob
+    else:
+        netG = netG.to(device=device)
+        fixed_noise = fixed_noise.to(device=device)
+
+    labels = np.array([num for _ in range(10) for num in range(10)])
+    labels = Variable(LongTensor(labels))
+
+    # quantize model
+    if opt.precision == 'int8':
+        from lpot.experimental import Quantization, common
+        quantizer = Quantization((opt.config_file))
+        dataset = (fixed_noise, labels)
+        calib_dataloader = _DataLoader(dataset)
+        quantizer.calib_dataloader = calib_dataloader
+        quantizer.model = common.Model(netG)
+        q_model = quantizer()
+        netG = q_model.model
+
+    netG.eval()
+
+    if opt.jit:
+        netG = torch.jit.trace(netG, (fixed_noise, labels))
+    with torch.no_grad():
+        for i in range(opt.num_warmup + opt.num_iterations):
+            if i == opt.num_warmup:
+                tic = time.time()
+            if opt.profile:
+                with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU]) as prof:
+                    if opt.precision == "bfloat16":
+                        with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                            fake = netG(fixed_noise, labels)
+                    else:
+                        fake = netG(fixed_noise, labels)
+            else:
+                if opt.precision == "bfloat16":
+                    with torch.cpu.amp.autocast(enabled=True, dtype=torch.bfloat16):
+                        fake = netG(fixed_noise, labels)
+                else:
+                    fake = netG(fixed_noise, labels)
+    toc = time.time() - tic
+    print("Throughput: %.2f image/sec, batchsize: %d, latency = %.2f ms"%((opt.num_iterations*batchsize)/toc, batchsize, 1000*toc/opt.num_iterations))
+    #
+    if opt.profile:
+        import pathlib
+        timeline_dir = str(pathlib.Path.cwd()) + '/timeline/'
+        if not os.path.exists(timeline_dir):
+            os.makedirs(timeline_dir)
+        timeline_file = timeline_dir + 'timeline-' + str(torch.backends.quantized.engine) + '-' + \
+                    opt.arch + '-' + str(i + 1) + '-' + str(os.getpid()) + '.json'
+        prof.export_chrome_trace(timeline_file)
+        # table_res = prof.key_averages().table(sort_by="cpu_time_total")
+        # save_profile_result(timeline_dir + torch.backends.quantized.engine + "_result_average.xlsx", table_res)
+
+
 def sample_image(n_row, batches_done):
     """Saves a grid of generated digits ranging from 0 to n_classes"""
     # Sample noise
@@ -156,10 +268,18 @@ def sample_image(n_row, batches_done):
     # Get labels ranging from 0 to n_classes for n rows
     labels = np.array([num for _ in range(n_row) for num in range(n_row)])
     labels = Variable(LongTensor(labels))
+
     gen_imgs = generator(z, labels)
     save_image(gen_imgs.data, "images/%d.png" % batches_done, nrow=n_row, normalize=True)
 
 
+if opt.inference:
+    print("----------------Generation benchmarking---------------")
+    generate(generator, opt.batch_size, device=torch.device(device))
+    import sys
+    sys.exit(0)
+
+
 # ----------
 #  Training
 # ----------
@@ -229,3 +349,7 @@ for epoch in range(opt.n_epochs):
         batches_done = epoch * len(dataloader) + i
         if batches_done % opt.sample_interval == 0:
             sample_image(n_row=10, batches_done=batches_done)
+    
+    torch.save(generator.state_dict(), '%s/generator.pth' % opt.outf)
+    torch.save(discriminator.state_dict(), '%s/discriminator.pth' % opt.outf)
+
