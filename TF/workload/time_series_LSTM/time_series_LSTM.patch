diff --git a/build_model.py b/build_model.py
index be2d655..448b6e9 100644
--- a/build_model.py
+++ b/build_model.py
@@ -7,11 +7,11 @@ def rnn_lstm(layers, params):
 	"""Build RNN (LSTM) model on top of Keras and Tensorflow"""
 
 	model = Sequential()
-	model.add(LSTM(input_shape=(layers[1], layers[0]), output_dim=layers[1], return_sequences=True))
+	model.add(LSTM(100, input_shape=(layers[1], layers[0]), return_sequences=True))
 	model.add(Dropout(params['dropout_keep_prob']))
 	model.add(LSTM(layers[2], return_sequences=False))
 	model.add(Dropout(params['dropout_keep_prob']))
-	model.add(Dense(output_dim=layers[3]))
+	model.add(Dense(layers[3]))
 	model.add(Activation("tanh"))
 
 	model.compile(loss="mean_squared_error", optimizer="rmsprop")
diff --git a/train_predict.py b/train_predict.py
index 3bb84c9..da4dae5 100644
--- a/train_predict.py
+++ b/train_predict.py
@@ -5,51 +5,90 @@ import data_helper
 import numpy as np
 import pandas as pd
 import matplotlib.pyplot as plt
+import argparse
+import time
+
 
 def train_predict():
-	"""Train and predict time series data"""
-
-	# Load command line arguments 
-	train_file = sys.argv[1]
-	parameter_file = sys.argv[2]
-
-	# Load training parameters
-	params = json.loads(open(parameter_file).read())
-
-	# Load time series dataset, and split it into train and test
-	x_train, y_train, x_test, y_test, x_test_raw, y_test_raw,\
-		last_window_raw, last_window = data_helper.load_timeseries(train_file, params)
-
-	# Build RNN (LSTM) model
-	lstm_layer = [1, params['window_size'], params['hidden_unit'], 1]
-	model = build_model.rnn_lstm(lstm_layer, params)
-
-	# Train RNN (LSTM) model with train set
-	model.fit(
-		x_train,
-		y_train,
-		batch_size=params['batch_size'],
-		epochs=params['epochs'],
-		validation_split=params['validation_split'])
-
-	# Check the model against test set
-	predicted = build_model.predict_next_timestamp(model, x_test)        
-	predicted_raw = []
-	for i in range(len(x_test_raw)):
-		predicted_raw.append((predicted[i] + 1) * x_test_raw[i][0])
-
-	# Plot graph: predicted VS actual
-	plt.subplot(111)
-	plt.plot(predicted_raw, label='Actual')
-	plt.plot(y_test_raw, label='Predicted')	
-	plt.legend()
-	plt.show()
-
-	# Predict next time stamp 
-	next_timestamp = build_model.predict_next_timestamp(model, last_window)
-	next_timestamp_raw = (next_timestamp[0] + 1) * last_window_raw[0][0]
-	print('The next time stamp forecasting is: {}'.format(next_timestamp_raw))
+       """Train and predict time series data"""
+
+       # Load command line arguments 
+       #train_file = sys.argv[1]
+       #parameter_file = sys.argv[2]
+       #num_iter = sys.argv[3]
+       #num_warmup = sys.argv[4]
+
+       # Load training parameters
+       params = json.loads(open(parameter_file).read())
+
+       # Load time series dataset, and split it into train and test
+       x_train, y_train, x_test, y_test, x_test_raw, y_test_raw,\
+       	last_window_raw, last_window = data_helper.load_timeseries(train_file, params)
+
+       # Build RNN (LSTM) model
+       lstm_layer = [1, params['window_size'], params['hidden_unit'], 1]
+       model = build_model.rnn_lstm(lstm_layer, params)
+
+       # Train RNN (LSTM) model with train set
+       model.fit(
+       	x_train,
+       	y_train,
+       	batch_size=params['batch_size'],
+       	epochs=params['epochs'],
+       	validation_split=params['validation_split'])
+
+       # Check the model against test set
+       predicted = build_model.predict_next_timestamp(model, x_test)        
+       predicted_raw = []
+       for i in range(len(x_test_raw)):
+       	predicted_raw.append((predicted[i] + 1) * x_test_raw[i][0])
+
+       # Plot graph: predicted VS actual
+       plt.subplot(111)
+       plt.plot(predicted_raw, label='Actual')
+       plt.plot(y_test_raw, label='Predicted')	
+       plt.legend()
+       plt.show()
+
+       total_time = 0.0
+       iter_done = 0
+       for i in range(num_iter):
+           if i < num_warmup:
+               # Predict next time stamp
+               next_timestamp = build_model.predict_next_timestamp(model, last_window)
+               next_timestamp_raw = (next_timestamp[0] + 1) * last_window_raw[0][0]
+               print('The next time stamp forecasting is: {}'.format(next_timestamp_raw))
+               continue
+           start = time.time()
+           # Predict next time stamp
+           next_timestamp = build_model.predict_next_timestamp(model, last_window)
+           next_timestamp_raw = (next_timestamp[0] + 1) * last_window_raw[0][0]
+           print('The next time stamp forecasting is: {}'.format(next_timestamp_raw))
+            
+           cost = time.time() - start
+           total_time += cost
+           iter_done += 1
+           print('Iteration done: {:.2f}'.format(iter_done))
+
+       print('Total time: {:.2f}'.format(total_time))
+       print('Throughput: {:.2f}'.format(iter_done / total_time))
+
 
 if __name__ == '__main__':
-	# python3 train_predict.py ./data/sales.csv ./training_config.json_
-	train_predict()
+
+       parser = argparse.ArgumentParser(description='Tensorflow time series LSTM evaluation')
+       parser.add_argument("--train_file", help="path of train file")
+       parser.add_argument("--parameter_file", help="path of parameter file")
+       parser.add_argument('-n', '--num_iter', default=500, type=int,
+                           help='numbers of inference iteration (default: 500)')
+       parser.add_argument('--num_warmup', default=10, type=int,
+                           help='numbers of warmup iteration, default is 10')
+
+       args = parser.parse_args()
+       train_file = args.train_file
+       parameter_file = args.parameter_file
+       num_iter = args.num_iter
+       num_warmup = args.num_warmup
+
+       # python3 train_predict.py ./data/sales.csv ./training_config.json_
+       train_predict()
diff --git a/training_config.json b/training_config.json
index 36c9156..b6f46cf 100644
--- a/training_config.json
+++ b/training_config.json
@@ -1,6 +1,6 @@
 {
-	"epochs": 100,
-	"batch_size": 2,
+	"epochs": 1,
+	"batch_size": 1,
 	"window_size": 6,
 	"train_test_split": 0.8,
 	"validation_split": 0.1,
